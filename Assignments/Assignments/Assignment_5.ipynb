{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment-5 (75 marks)"
      ],
      "metadata": {
        "id": "4WumCmI8VY2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#General Information\n",
        "\n",
        "Welcome to Assignment 5. We will be applying the concepts we have learned so far to solve this assignment.Goodluck!\n",
        "\n",
        "Please fill out your name and email in the below cell\n",
        "\n"
      ],
      "metadata": {
        "id": "wVJJI3TZVY0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NAME : \n",
        "#EMAIL :"
      ],
      "metadata": {
        "id": "gBIVDdCMVoWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1 (10 Marks)"
      ],
      "metadata": {
        "id": "FHRgbA-iVtFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**\"Differentiate Value Based methods and Policy Based methods in brief\"**"
      ],
      "metadata": {
        "id": "Xn3vEqbaV33N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2 (15 marks)"
      ],
      "metadata": {
        "id": "PdSX96bFWjPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**\"Briefly explain intuition of Actor Critic Method with drawbacks\"**"
      ],
      "metadata": {
        "id": "kOdRjJnEWpPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3 (50 Marks) (code)\n",
        "\n",
        "**\"Implement Training and evaluate of \"Lunar Landar\" RL Environment using Deep Q Network Algorithm and stable baselines 3\"**\n",
        "\n",
        "Make sure your answers in foloowing steps\n",
        "\n",
        "\n",
        "> Step 1: Installing necessary packages and Importing Dependencies(Import policy, RL agent)\n",
        "\n",
        "> Step 2: Create the Gym env and instantiate the agent\n",
        "\n",
        "> Step 3: Evaluate the un-trained agent\n",
        "\n",
        "> Step 4: Train the agent and save it\n",
        "\n",
        "> Step 5: Load the trained agent and obtain Mean Reward\n",
        "\n",
        "Use the following links for reference:\n",
        "\n",
        " https://gym.openai.com/envs/LunarLander-v2/\n",
        "\n",
        "\n",
        " https://stable-baselines3.readthedocs.io/en/master/guide/examples.html \n",
        "\n",
        " Note: Ignore the environment rendering and Visualization.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6eZFpak0dGCa"
      }
    }
  ]
}